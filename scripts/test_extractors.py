#!/usr/bin/env python3
"""Integration test for extractors using real data and Qwen-plus LLM."""

import asyncio
from pathlib import Path

from offer_sherlock.extractors import JobExtractor, InsightExtractor
from offer_sherlock.crawlers import XhsCrawler
from offer_sherlock.llm.client import LLMClient
from offer_sherlock.utils.config import LLMProvider


async def test_job_extractor():
    """Test JobExtractor with real crawled data."""
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯• JobExtractor - ä»å®˜ç½‘å†…å®¹æå–å²—ä½ä¿¡æ¯")
    print("=" * 60)

    # Read sample crawled content
    data_dir = Path(__file__).parent.parent / "data" / "crawl_results"

    # Test with Apple jobs page
    apple_file = data_dir / "Apple.md"
    if apple_file.exists():
        print(f"\nğŸ“– è¯»å–: {apple_file.name}")
        content = apple_file.read_text()[:10000]  # Limit content size

        # Create extractor with Qwen-plus
        llm = LLMClient(provider=LLMProvider.QWEN, model="qwen-plus")
        extractor = JobExtractor(llm_client=llm)

        print("ğŸ¤– ä½¿ç”¨ Qwen-plus æå–å²—ä½ä¿¡æ¯...")
        result = await extractor.extract(
            content=content,
            company="Apple",
            source_url="https://jobs.apple.com/en-us/search",
        )

        print(f"\nâœ… æå–ç»“æœ: æ‰¾åˆ° {result.count} ä¸ªå²—ä½")
        for i, job in enumerate(result.jobs[:5], 1):
            print(f"\n[{i}] {job.title}")
            print(f"    å…¬å¸: {job.company}")
            print(f"    åœ°ç‚¹: {job.location or 'æœªçŸ¥'}")
            print(f"    ç±»å‹: {job.job_type or 'æœªçŸ¥'}")
            print(f"    ID: {job.job_id_external or 'æœªçŸ¥'}")
            if job.requirements:
                print(f"    è¦æ±‚: {job.requirements[:80]}...")

        if result.extraction_notes:
            print(f"\nğŸ“ æå–è¯´æ˜: {result.extraction_notes}")

    # Test with Chinese company
    print("\n" + "-" * 60)
    huawei_file = data_dir / "åä¸º.md"
    if huawei_file.exists():
        print(f"\nğŸ“– è¯»å–: {huawei_file.name}")
        content = huawei_file.read_text()[:10000]

        result = await extractor.extract(
            content=content,
            company="åä¸º",
            source_url="https://career.huawei.com/reccampportal/portal5/campus-recruitment.html",
        )

        print(f"\nâœ… æå–ç»“æœ: æ‰¾åˆ° {result.count} ä¸ªå²—ä½")
        for i, job in enumerate(result.jobs[:5], 1):
            print(f"\n[{i}] {job.title}")
            print(f"    åœ°ç‚¹: {job.location or 'æœªçŸ¥'}")
            print(f"    ç±»å‹: {job.job_type or 'æœªçŸ¥'}")


async def test_insight_extractor():
    """Test InsightExtractor with XHS notes."""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯• InsightExtractor - ä»å°çº¢ä¹¦å†…å®¹æå–æƒ…æŠ¥")
    print("=" * 60)

    # Create XHS crawler and search
    print("\nğŸ” æœç´¢å°çº¢ä¹¦: å­—èŠ‚è·³åŠ¨ offer")

    async with XhsCrawler(headless=True) as crawler:
        notes = await crawler.search("å­—èŠ‚è·³åŠ¨ offer", max_results=5)

        if not notes:
            print("âŒ æœªæ‰¾åˆ°ç¬”è®°ï¼Œè·³è¿‡æµ‹è¯•")
            return

        print(f"ğŸ“– æ‰¾åˆ° {len(notes)} æ¡ç¬”è®°")

        # Create extractor
        llm = LLMClient(provider=LLMProvider.QWEN, model="qwen-plus")
        extractor = InsightExtractor(llm_client=llm)

        # Extract and analyze
        print("\nğŸ¤– ä½¿ç”¨ Qwen-plus åˆ†æç¬”è®°...")
        summary = await extractor.analyze_notes(
            notes=notes,
            company="å­—èŠ‚è·³åŠ¨",
            position_keyword="offer",
        )

        # Print results
        print("\n" + "=" * 60)
        print("ğŸ“Š æƒ…æŠ¥æ±‡æ€»")
        print("=" * 60)
        print(summary.to_markdown())

        print("\nğŸ“ æ¥æºå¸–å­:")
        for i, post in enumerate(summary.source_posts[:5], 1):
            sentiment_map = {"positive": "ğŸ‘", "negative": "ğŸ‘", "neutral": "â–"}
            emoji = sentiment_map.get(post.sentiment.value, "â–")
            print(f"  [{i}] {emoji} {post.title[:40]}... ({post.likes} èµ)")
            if post.mentioned_salary:
                print(f"       ğŸ’° è–ªèµ„: {post.mentioned_salary}")


async def main():
    """Run all integration tests."""
    print("ğŸš€ Offer-Sherlock æå–å™¨é›†æˆæµ‹è¯•")
    print("   ä½¿ç”¨ Qwen-plus ä½œä¸º LLM\n")

    try:
        await test_job_extractor()
    except Exception as e:
        print(f"âŒ JobExtractor æµ‹è¯•å¤±è´¥: {e}")

    try:
        await test_insight_extractor()
    except Exception as e:
        print(f"âŒ InsightExtractor æµ‹è¯•å¤±è´¥: {e}")

    print("\nâœ… é›†æˆæµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    asyncio.run(main())
