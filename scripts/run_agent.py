#!/usr/bin/env python3
"""CLI script to run the intelligence collection agent.

Usage:
    # Single company with official URL
    python scripts/run_agent.py --company "å­—èŠ‚è·³åŠ¨" --url "https://jobs.bytedance.com"

    # Single company, social only
    python scripts/run_agent.py --company "è…¾è®¯" --skip-official

    # Batch mode (all active targets)
    python scripts/run_agent.py --all

    # Add a new crawl target
    python scripts/run_agent.py --add-target --company "åä¸º" --url "https://career.huawei.com"
"""

import argparse
import asyncio
import logging
import sys
from pathlib import Path

from offer_sherlock.agents import IntelAgent, AgentResult
from offer_sherlock.database import (
    DatabaseManager,
    CrawlTargetRepository,
    JobRepository,
    InsightRepository,
)


def setup_logging(verbose: bool = False):
    """Configure logging."""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )


def print_result(result: AgentResult):
    """Print a single result in a nice format."""
    print(f"\n{result}")
    if result.errors:
        for error in result.errors:
            print(f"  âš ï¸  {error}")


def print_summary(results: list[AgentResult]):
    """Print summary of batch results."""
    print("\n" + "=" * 60)
    print("ğŸ“Š è¿è¡Œç»“æœæ±‡æ€»")
    print("=" * 60)

    successful = [r for r in results if r.success]
    failed = [r for r in results if not r.success]

    print(f"\næ€»å…¬å¸æ•°: {len(results)}")
    print(f"æˆåŠŸ: {len(successful)}")
    print(f"å¤±è´¥: {len(failed)}")

    total_jobs = sum(r.jobs_added for r in results)
    total_insights = sum(1 for r in results if r.insight_generated)
    total_time = sum(r.duration_seconds for r in results)

    print(f"\næ–°å¢å²—ä½: {total_jobs}")
    print(f"ç”Ÿæˆæƒ…æŠ¥: {total_insights}")
    print(f"æ€»è€—æ—¶: {total_time:.1f}s")

    if failed:
        print("\nâŒ å¤±è´¥çš„å…¬å¸:")
        for r in failed:
            print(f"  - {r.company}: {', '.join(r.errors)}")


async def run_single(
    db: DatabaseManager,
    company: str,
    url: str = None,
    skip_official: bool = False,
    skip_social: bool = False,
    headless: bool = True,
):
    """Run agent for a single company."""
    print(f"\nğŸš€ å¼€å§‹æ”¶é›† {company} æƒ…æŠ¥...")

    agent = IntelAgent(db, xhs_headless=headless)
    result = await agent.run(
        company=company,
        official_url=url,
        skip_official=skip_official,
        skip_social=skip_social,
    )

    print_result(result)
    return result


async def run_batch(
    db: DatabaseManager,
    max_companies: int = None,
    headless: bool = True,
):
    """Run agent for all active targets."""
    with db.session() as session:
        target_repo = CrawlTargetRepository(session)
        targets = target_repo.list_active()

    if not targets:
        print("âŒ æ²¡æœ‰æ´»è·ƒçš„æŠ“å–ç›®æ ‡")
        print("   ä½¿ç”¨ --add-target æ·»åŠ ç›®æ ‡")
        return []

    count = len(targets) if not max_companies else min(len(targets), max_companies)
    print(f"\nğŸš€ å¼€å§‹æ‰¹é‡æ”¶é›† {count} å®¶å…¬å¸æƒ…æŠ¥...")

    agent = IntelAgent(db, xhs_headless=headless)
    results = await agent.run_all(max_companies=max_companies)

    for result in results:
        print_result(result)

    print_summary(results)
    return results


def add_target(db: DatabaseManager, company: str, url: str, crawler_type: str = "official"):
    """Add a new crawl target."""
    with db.session() as session:
        repo = CrawlTargetRepository(session)

        # Check if already exists
        existing = repo.list_by_company(company)
        for t in existing:
            if t.url == url:
                print(f"âš ï¸  ç›®æ ‡å·²å­˜åœ¨: {company} - {url}")
                return

        repo.add(company=company, url=url, crawler_type=crawler_type)
        print(f"âœ… å·²æ·»åŠ ç›®æ ‡: {company} - {url}")


def list_targets(db: DatabaseManager):
    """List all crawl targets."""
    with db.session() as session:
        repo = CrawlTargetRepository(session)
        targets = repo.list_all()

    print("\nğŸ“‹ æŠ“å–ç›®æ ‡åˆ—è¡¨")
    print("=" * 60)

    if not targets:
        print("(ç©º)")
        return

    for t in targets:
        status = "âœ…" if t.is_active else "â¸ï¸"
        last = t.last_crawled_at.strftime("%Y-%m-%d %H:%M") if t.last_crawled_at else "ä»æœª"
        print(f"{status} {t.company}")
        print(f"   URL: {t.url}")
        print(f"   ç±»å‹: {t.crawler_type} | ä¸Šæ¬¡æŠ“å–: {last}")
        print()


def show_stats(db: DatabaseManager):
    """Show database statistics."""
    with db.session() as session:
        job_repo = JobRepository(session)
        insight_repo = InsightRepository(session)
        target_repo = CrawlTargetRepository(session)

        print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡")
        print("=" * 60)
        print(f"æ€»å²—ä½æ•°: {job_repo.count()}")
        print(f"æ€»æƒ…æŠ¥æ•°: {insight_repo.count()}")
        print(f"æŠ“å–ç›®æ ‡: {len(target_repo.list_all())} (æ´»è·ƒ: {len(target_repo.list_active())})")

        # Top companies by job count
        from sqlalchemy import select, func
        from offer_sherlock.database.models import Job

        stmt = (
            select(Job.company, func.count(Job.id).label("count"))
            .group_by(Job.company)
            .order_by(func.count(Job.id).desc())
            .limit(5)
        )
        top_companies = list(session.execute(stmt))

        if top_companies:
            print("\nå²—ä½æ•° Top 5:")
            for company, count in top_companies:
                print(f"  - {company}: {count}")


def main():
    parser = argparse.ArgumentParser(
        description="Offer-Sherlock æƒ…æŠ¥æ”¶é›† Agent",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å•å…¬å¸æ¨¡å¼
  python scripts/run_agent.py --company "å­—èŠ‚è·³åŠ¨" --url "https://jobs.bytedance.com"

  # åªæŠ“å–ç¤¾äº¤æƒ…æŠ¥
  python scripts/run_agent.py --company "è…¾è®¯" --skip-official

  # æ‰¹é‡æ¨¡å¼
  python scripts/run_agent.py --all

  # æ·»åŠ æŠ“å–ç›®æ ‡
  python scripts/run_agent.py --add-target --company "åä¸º" --url "https://career.huawei.com"

  # æŸ¥çœ‹çŠ¶æ€
  python scripts/run_agent.py --list-targets
  python scripts/run_agent.py --stats
        """,
    )

    # Mode selection
    mode_group = parser.add_mutually_exclusive_group()
    mode_group.add_argument(
        "--company", "-c",
        help="å•å…¬å¸æ¨¡å¼: æŒ‡å®šå…¬å¸åç§°",
    )
    mode_group.add_argument(
        "--all", "-a",
        action="store_true",
        help="æ‰¹é‡æ¨¡å¼: è¿è¡Œæ‰€æœ‰æ´»è·ƒç›®æ ‡",
    )
    mode_group.add_argument(
        "--add-target",
        action="store_true",
        help="æ·»åŠ æ–°çš„æŠ“å–ç›®æ ‡",
    )
    mode_group.add_argument(
        "--list-targets",
        action="store_true",
        help="åˆ—å‡ºæ‰€æœ‰æŠ“å–ç›®æ ‡",
    )
    mode_group.add_argument(
        "--stats",
        action="store_true",
        help="æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡",
    )

    # Options
    parser.add_argument(
        "--url", "-u",
        help="å®˜ç½‘æ‹›è˜ URL",
    )
    parser.add_argument(
        "--skip-official",
        action="store_true",
        help="è·³è¿‡å®˜ç½‘æŠ“å–",
    )
    parser.add_argument(
        "--skip-social",
        action="store_true",
        help="è·³è¿‡ç¤¾äº¤æƒ…æŠ¥",
    )
    parser.add_argument(
        "--max-companies", "-m",
        type=int,
        help="æ‰¹é‡æ¨¡å¼: æœ€å¤§å…¬å¸æ•°",
    )
    parser.add_argument(
        "--db",
        default="data/offers.db",
        help="æ•°æ®åº“è·¯å¾„ (é»˜è®¤: data/offers.db)",
    )
    parser.add_argument(
        "--no-headless",
        action="store_true",
        help="æ˜¾ç¤ºæµè§ˆå™¨çª—å£ (ç”¨äºè°ƒè¯•)",
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—",
    )

    args = parser.parse_args()

    # Setup
    setup_logging(args.verbose)
    db = DatabaseManager(db_path=args.db)
    db.create_tables()

    # Execute
    if args.list_targets:
        list_targets(db)
    elif args.stats:
        show_stats(db)
    elif args.add_target:
        if not args.company or not args.url:
            print("âŒ æ·»åŠ ç›®æ ‡éœ€è¦ --company å’Œ --url")
            sys.exit(1)
        add_target(db, args.company, args.url)
    elif args.all:
        asyncio.run(run_batch(
            db,
            max_companies=args.max_companies,
            headless=not args.no_headless,
        ))
    elif args.company:
        asyncio.run(run_single(
            db,
            company=args.company,
            url=args.url,
            skip_official=args.skip_official,
            skip_social=args.skip_social,
            headless=not args.no_headless,
        ))
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
