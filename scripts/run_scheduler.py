#!/usr/bin/env python3
"""Run the intelligence collection scheduler.

This script starts the IntelScheduler to periodically collect job postings
and social intelligence from configured crawl targets.

Usage:
    # Default: Run at 9AM and 9PM on weekdays
    python scripts/run_scheduler.py

    # Run every 6 hours
    python scripts/run_scheduler.py --interval 6

    # Custom cron schedule (8AM, 2PM, 8PM daily)
    python scripts/run_scheduler.py --cron-hour "8,14,20" --cron-day "*"

    # Run immediately, then continue on schedule
    python scripts/run_scheduler.py --run-now

    # Skip social media crawling
    python scripts/run_scheduler.py --skip-social

    # Show status and exit
    python scripts/run_scheduler.py --status
"""

import argparse
import asyncio
import logging
import sys
from datetime import datetime
from pathlib import Path

from offer_sherlock.scheduler import IntelScheduler, ScheduleConfig
from offer_sherlock.database import DatabaseManager, CrawlTargetRepository

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


def show_status(db_path: str):
    """Show current targets and database status."""
    db = DatabaseManager(db_path=db_path)

    with db.session() as session:
        repo = CrawlTargetRepository(session)
        targets = repo.list_active()

        print("\nğŸ“‹ æ´»è·ƒæŠ“å–ç›®æ ‡")
        print("=" * 60)

        if not targets:
            print("(æ— æ´»è·ƒç›®æ ‡ - è¿è¡Œ python scripts/init_targets.py åˆå§‹åŒ–)")
            return

        for t in targets:
            last_crawled = t.last_crawled_at.strftime("%Y-%m-%d %H:%M") if t.last_crawled_at else "ä»æœª"
            print(f"  {t.company:<12} | ä¸Šæ¬¡æŠ“å–: {last_crawled}")

        print(f"\næ€»è®¡: {len(targets)} ä¸ªæ´»è·ƒç›®æ ‡")


def on_collection_complete(results):
    """Callback when collection completes."""
    successful = sum(1 for r in results if r.success)
    jobs_added = sum(r.jobs_added for r in results)
    insights = sum(1 for r in results if r.insight_generated)

    print(f"\n{'=' * 60}")
    print(f"âœ… é‡‡é›†å®Œæˆ: {successful}/{len(results)} æˆåŠŸ")
    print(f"   æ–°å¢å²—ä½: {jobs_added}")
    print(f"   ç”Ÿæˆæƒ…æŠ¥: {insights}")
    print(f"{'=' * 60}\n")


def on_collection_error(error):
    """Callback when collection fails."""
    print(f"\nâŒ é‡‡é›†å¤±è´¥: {error}\n")


async def main():
    parser = argparse.ArgumentParser(
        description="è¿è¡Œæƒ…æŠ¥æ”¶é›†è°ƒåº¦å™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )

    # Schedule options
    schedule_group = parser.add_argument_group("è°ƒåº¦é€‰é¡¹")
    schedule_group.add_argument(
        "--interval",
        type=float,
        help="æ¯ N å°æ—¶è¿è¡Œä¸€æ¬¡ (è¦†ç›– cron è®¾ç½®)",
    )
    schedule_group.add_argument(
        "--cron-hour",
        default="9,21",
        help="è¿è¡Œæ—¶é—´ (cron æ ¼å¼, é»˜è®¤: 9,21 å³ 9AM å’Œ 9PM)",
    )
    schedule_group.add_argument(
        "--cron-minute",
        default="0",
        help="è¿è¡Œåˆ†é’Ÿ (é»˜è®¤: 0)",
    )
    schedule_group.add_argument(
        "--cron-day",
        default="mon-fri",
        help="è¿è¡Œæ—¥æœŸ (cron æ ¼å¼, é»˜è®¤: mon-fri, ç”¨ * è¡¨ç¤ºæ¯å¤©)",
    )
    schedule_group.add_argument(
        "--timezone",
        default="Asia/Shanghai",
        help="æ—¶åŒº (é»˜è®¤: Asia/Shanghai)",
    )

    # Collection options
    collect_group = parser.add_argument_group("é‡‡é›†é€‰é¡¹")
    collect_group.add_argument(
        "--skip-social",
        action="store_true",
        help="è·³è¿‡ç¤¾äº¤åª’ä½“æŠ“å– (å°çº¢ä¹¦)",
    )
    collect_group.add_argument(
        "--max-companies",
        type=int,
        help="æ¯æ¬¡è¿è¡Œæœ€å¤šå¤„ç†å…¬å¸æ•°",
    )
    collect_group.add_argument(
        "--delay",
        type=float,
        default=2.0,
        help="å…¬å¸é—´å»¶è¿Ÿç§’æ•° (é»˜è®¤: 2.0)",
    )

    # Database options
    db_group = parser.add_argument_group("æ•°æ®åº“é€‰é¡¹")
    db_group.add_argument(
        "--db",
        default="data/offers.db",
        help="æ•°æ®åº“è·¯å¾„ (é»˜è®¤: data/offers.db)",
    )

    # Actions
    action_group = parser.add_argument_group("æ“ä½œ")
    action_group.add_argument(
        "--run-now",
        action="store_true",
        help="ç«‹å³è¿è¡Œä¸€æ¬¡ï¼Œç„¶åç»§ç»­æŒ‰è®¡åˆ’æ‰§è¡Œ",
    )
    action_group.add_argument(
        "--once",
        action="store_true",
        help="åªè¿è¡Œä¸€æ¬¡ï¼Œä¸å¯åŠ¨è°ƒåº¦å™¨",
    )
    action_group.add_argument(
        "--status",
        action="store_true",
        help="æ˜¾ç¤ºå½“å‰çŠ¶æ€å¹¶é€€å‡º",
    )

    args = parser.parse_args()

    # Ensure data directory exists
    Path(args.db).parent.mkdir(parents=True, exist_ok=True)

    # Show status and exit
    if args.status:
        show_status(args.db)
        return

    # Create configuration
    config = ScheduleConfig(
        db_path=args.db,
        skip_social=args.skip_social,
        max_companies_per_run=args.max_companies,
        delay_between_companies=args.delay,
        cron_hour=args.cron_hour,
        cron_minute=args.cron_minute,
        cron_day_of_week=args.cron_day if args.cron_day != "*" else "mon-sun",
        interval_hours=args.interval,
        timezone=args.timezone,
        on_complete=on_collection_complete,
        on_error=on_collection_error,
    )

    scheduler = IntelScheduler(config)

    # Run once mode
    if args.once:
        print("\nğŸš€ è¿è¡Œä¸€æ¬¡æƒ…æŠ¥é‡‡é›†...")
        print("=" * 60)
        results = await scheduler.run_once()

        print("\nğŸ“Š é‡‡é›†ç»“æœ")
        print("-" * 60)
        for r in results:
            print(str(r))

        successful = sum(1 for r in results if r.success)
        print(f"\nâœ… å®Œæˆ: {successful}/{len(results)} æˆåŠŸ")
        return

    # Start scheduler
    print("\nğŸ• å¯åŠ¨æƒ…æŠ¥é‡‡é›†è°ƒåº¦å™¨")
    print("=" * 60)
    print(f"æ•°æ®åº“: {args.db}")

    if args.interval:
        print(f"è°ƒåº¦: æ¯ {args.interval} å°æ—¶")
    else:
        day_str = "æ¯å¤©" if args.cron_day in ("*", "mon-sun") else args.cron_day
        print(f"è°ƒåº¦: {args.cron_hour}:{args.cron_minute} ({day_str})")

    print(f"æ—¶åŒº: {args.timezone}")
    print(f"è·³è¿‡ç¤¾äº¤: {'æ˜¯' if args.skip_social else 'å¦'}")

    if args.max_companies:
        print(f"æ¯æ¬¡æœ€å¤š: {args.max_companies} å®¶å…¬å¸")

    # Run immediately if requested
    if args.run_now:
        print("\nâš¡ ç«‹å³æ‰§è¡Œé¦–æ¬¡é‡‡é›†...")
        await scheduler.run_once()

    # Start the scheduler
    scheduler.start()

    next_run = scheduler.get_next_run_time()
    if next_run:
        print(f"\nâ° ä¸‹æ¬¡è¿è¡Œ: {next_run.strftime('%Y-%m-%d %H:%M:%S')}")

    print("\næŒ‰ Ctrl+C åœæ­¢è°ƒåº¦å™¨\n")

    # Keep running
    try:
        while True:
            await asyncio.sleep(60)

            # Periodic status update
            status = scheduler.get_status()
            if status["run_count"] > 0:
                next_run = scheduler.get_next_run_time()
                if next_run:
                    remaining = (next_run - datetime.now(next_run.tzinfo)).total_seconds()
                    if remaining > 0:
                        hours, remainder = divmod(int(remaining), 3600)
                        minutes, _ = divmod(remainder, 60)
                        # Only log occasionally
                        if minutes == 0:
                            logger.debug(f"ä¸‹æ¬¡è¿è¡Œ: {hours}h {minutes}m")

    except KeyboardInterrupt:
        print("\n\nğŸ›‘ æ­£åœ¨åœæ­¢è°ƒåº¦å™¨...")
        scheduler.shutdown()
        print("âœ… è°ƒåº¦å™¨å·²åœæ­¢")


if __name__ == "__main__":
    asyncio.run(main())
