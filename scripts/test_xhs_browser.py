#!/usr/bin/env python3
"""
ä½¿ç”¨ Playwright æµè§ˆå™¨ç›´æ¥è®¿é—®å°çº¢ä¹¦æœç´¢é¡µé¢è·å–æ•°æ®ã€‚

è¿™ç§æ–¹å¼éœ€è¦å…ˆç™»å½•ï¼Œç„¶ååœ¨åŒä¸€ä¼šè¯ä¸­è¿›è¡Œæœç´¢ã€‚
"""

import asyncio
import json
import os
import re
import sys
from pathlib import Path
from urllib.parse import quote

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from playwright.async_api import async_playwright


async def search_xhs_with_login(keyword: str, max_results: int = 10):
    """ç™»å½•åæœç´¢å°çº¢ä¹¦ç¬”è®°ã€‚"""

    print("=" * 60)
    print("ğŸ” å°çº¢ä¹¦æµè§ˆå™¨æœç´¢")
    print("=" * 60)
    print()
    print("1. æµè§ˆå™¨å°†æ‰“å¼€å°çº¢ä¹¦")
    print("2. è¯·ç™»å½•ï¼ˆå¦‚æœéœ€è¦ï¼‰")
    print("3. ç™»å½•åè„šæœ¬ä¼šè‡ªåŠ¨æœç´¢å¹¶æå–ç»“æœ")
    print()

    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=False,  # æ˜¾ç¤ºæµè§ˆå™¨æ–¹ä¾¿ç™»å½•
            args=["--disable-blink-features=AutomationControlled"],
        )
        context = await browser.new_context(
            viewport={"width": 1280, "height": 800},
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        )

        page = await context.new_page()

        # è®¿é—®é¦–é¡µ
        print("ğŸŒ æ‰“å¼€å°çº¢ä¹¦é¦–é¡µ...")
        await page.goto("https://www.xiaohongshu.com", wait_until="domcontentloaded")
        await asyncio.sleep(2)

        # æ£€æŸ¥ç™»å½•çŠ¶æ€ï¼Œç­‰å¾…ç”¨æˆ·ç™»å½•
        print("\nâ³ æ£€æµ‹ç™»å½•çŠ¶æ€...")
        print("   å¦‚æœéœ€è¦ç™»å½•ï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­å®Œæˆç™»å½•")
        print("   æœ€é•¿ç­‰å¾… 3 åˆ†é’Ÿ\n")

        max_wait = 180
        waited = 0
        while waited < max_wait:
            cookies = await context.cookies()
            cookie_names = [c["name"] for c in cookies]
            if "web_session" in cookie_names:
                print("âœ… å·²ç™»å½•ï¼")
                break
            await asyncio.sleep(2)
            waited += 2
            if waited % 30 == 0:
                print(f"   ç­‰å¾…ä¸­... ({waited}ç§’)")
        else:
            print("âŒ ç™»å½•è¶…æ—¶")
            await browser.close()
            return []

        # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿çŠ¶æ€ç¨³å®š
        await asyncio.sleep(2)

        # æ‰§è¡Œæœç´¢
        print(f"\nğŸ” æœç´¢: {keyword}")
        encoded_keyword = quote(keyword)
        search_url = f"https://www.xiaohongshu.com/search_result?keyword={encoded_keyword}&source=web_search_result_notes"

        await page.goto(search_url, wait_until="domcontentloaded")
        print("   ç­‰å¾…æœç´¢ç»“æœåŠ è½½...")
        await asyncio.sleep(3)

        # æ£€æŸ¥æ˜¯å¦å¼¹å‡ºç™»å½•æ¡†
        login_modal = await page.query_selector('text="ç™»å½•åæŸ¥çœ‹æœç´¢ç»“æœ"')
        if login_modal:
            print("\nâš ï¸ éœ€è¦ç™»å½•æ‰èƒ½æŸ¥çœ‹æœç´¢ç»“æœ")
            print("   è¯·åœ¨æµè§ˆå™¨ä¸­å®Œæˆç™»å½•ï¼ˆæ‰«ç æˆ–æ‰‹æœºå·ï¼‰")
            print("   ç­‰å¾…ç™»å½•å®Œæˆ...\n")

            # ç­‰å¾…ç™»å½•æ¡†æ¶ˆå¤±
            max_wait = 120
            waited = 0
            while waited < max_wait:
                login_modal = await page.query_selector('text="ç™»å½•åæŸ¥çœ‹æœç´¢ç»“æœ"')
                if not login_modal:
                    print("âœ… ç™»å½•æˆåŠŸï¼")
                    await asyncio.sleep(3)
                    break
                await asyncio.sleep(2)
                waited += 2
                if waited % 20 == 0:
                    print(f"   ç­‰å¾…ä¸­... ({waited}ç§’)")
            else:
                print("âŒ ç™»å½•è¶…æ—¶")

        # ç­‰å¾…å†…å®¹åŠ è½½
        await asyncio.sleep(3)

        # æ»šåŠ¨é¡µé¢è§¦å‘æ‡’åŠ è½½
        await page.evaluate("window.scrollTo(0, 500)")
        await asyncio.sleep(2)

        # ä¿å­˜æˆªå›¾
        screenshot_path = Path("data/xhs_search_result.png")
        screenshot_path.parent.mkdir(parents=True, exist_ok=True)
        await page.screenshot(path=str(screenshot_path))
        print(f"   æˆªå›¾å·²ä¿å­˜: {screenshot_path}")

        # æå–æœç´¢ç»“æœ
        print("\nğŸ“– æå–æœç´¢ç»“æœ...")

        notes = []

        # æ–¹æ³•1: ä» __INITIAL_STATE__ æå–
        try:
            initial_state = await page.evaluate("""
                () => {
                    if (window.__INITIAL_STATE__) {
                        return JSON.stringify(window.__INITIAL_STATE__);
                    }
                    return null;
                }
            """)

            if initial_state:
                data = json.loads(initial_state)
                # æœç´¢ç»“æœé€šå¸¸åœ¨ search.notes æˆ– feed.notes ä¸­
                search_notes = data.get("search", {}).get("notes", [])
                if not search_notes:
                    search_notes = data.get("feed", {}).get("notes", [])

                for note in search_notes[:max_results]:
                    notes.append({
                        "note_id": note.get("id", ""),
                        "title": note.get("display_title", note.get("title", "æ— æ ‡é¢˜")),
                        "user": note.get("user", {}).get("nickname", ""),
                        "likes": note.get("liked_count", 0),
                        "type": note.get("type", ""),
                    })
                print(f"   ä» __INITIAL_STATE__ æå–åˆ° {len(notes)} æ¡")
        except Exception as e:
            print(f"   __INITIAL_STATE__ æå–å¤±è´¥: {e}")

        # æ–¹æ³•2: ä» DOM å…ƒç´ æå–
        if not notes:
            try:
                # å°çº¢ä¹¦æœç´¢ç»“æœçš„é€‰æ‹©å™¨
                note_elements = await page.query_selector_all('section.note-item, div[data-v-a264b01a].note-item, .feeds-page section')

                for elem in note_elements[:max_results]:
                    try:
                        # è·å–æ ‡é¢˜
                        title_el = await elem.query_selector('.title span, .note-content .title, a.title')
                        title = await title_el.inner_text() if title_el else ""

                        # è·å–ä½œè€…
                        author_el = await elem.query_selector('.author-wrapper .name, .user-info .name')
                        author = await author_el.inner_text() if author_el else ""

                        # è·å–é“¾æ¥
                        link_el = await elem.query_selector('a[href*="/explore/"]')
                        href = await link_el.get_attribute("href") if link_el else ""

                        if title or href:
                            note_id = ""
                            if href:
                                match = re.search(r'/explore/([a-f0-9]+)', href)
                                if match:
                                    note_id = match.group(1)

                            notes.append({
                                "note_id": note_id,
                                "title": title.strip() if title else "æ— æ ‡é¢˜",
                                "user": author.strip() if author else "",
                                "link": f"https://www.xiaohongshu.com{href}" if href else "",
                            })
                    except:
                        continue

                print(f"   ä» DOM æå–åˆ° {len(notes)} æ¡")
            except Exception as e:
                print(f"   DOM æå–å¤±è´¥: {e}")

        # æ–¹æ³•3: ä»ç½‘ç»œè¯·æ±‚ä¸­æå–
        if not notes:
            print("   å°è¯•åˆ·æ–°é¡µé¢å¹¶æ•è· API å“åº”...")

            api_response = []

            async def handle_response(response):
                if "/api/sns/web/v1/search/notes" in response.url:
                    try:
                        data = await response.json()
                        if data.get("success") and data.get("data", {}).get("items"):
                            api_response.extend(data["data"]["items"])
                    except:
                        pass

            page.on("response", handle_response)
            await page.reload(wait_until="networkidle")
            await asyncio.sleep(3)

            for item in api_response[:max_results]:
                note_card = item.get("note_card", {})
                notes.append({
                    "note_id": item.get("id", note_card.get("note_id", "")),
                    "title": note_card.get("display_title", "æ— æ ‡é¢˜"),
                    "user": note_card.get("user", {}).get("nickname", ""),
                    "likes": note_card.get("interact_info", {}).get("liked_count", 0),
                })
            print(f"   ä» API å“åº”æå–åˆ° {len(notes)} æ¡")

        await browser.close()
        return notes


async def main():
    keyword = "å­—èŠ‚è·³åŠ¨ é¢ç»"
    notes = await search_xhs_with_login(keyword)

    print("\n" + "=" * 60)
    print("ğŸ“Š æœç´¢ç»“æœ")
    print("=" * 60)

    if notes:
        print(f"\næ‰¾åˆ° {len(notes)} æ¡ç¬”è®°:\n")
        for i, note in enumerate(notes, 1):
            print(f"[{i}] {note.get('title', 'æ— æ ‡é¢˜')[:50]}")
            if note.get('user'):
                print(f"    ä½œè€…: {note['user']}")
            if note.get('likes'):
                print(f"    ç‚¹èµ: {note['likes']}")
            if note.get('note_id'):
                print(f"    ID: {note['note_id']}")
            print()
    else:
        print("\nâŒ æœªæ‰¾åˆ°æœç´¢ç»“æœ")
        print("è¯·æ£€æŸ¥ data/xhs_search_result.png æˆªå›¾")


if __name__ == "__main__":
    asyncio.run(main())
